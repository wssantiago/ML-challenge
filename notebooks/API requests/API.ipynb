{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad36748d-66b4-4031-9204-9ae88b846aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68910b15-1a32-4198-8614-7ad5c128a064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047bab4e-9147-4a16-aeed-07459680c93f",
   "metadata": {},
   "source": [
    "### 2. POST request on the `performance` endpoint for both regressor and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d728f5f-42dd-46af-b494-f3c97254545e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_test_file = open('classification_test.json')\n",
    "class_test_json = json.load(class_test_file)\n",
    "\n",
    "regr_test_file = open('regression_test.json')\n",
    "regr_test_json = json.load(regr_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e675b67-1d35-4606-a7ff-40e5ee1d24a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(class_test_json))\n",
    "print(type(regr_test_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36802de-fff9-4b47-a426-5d4c35835a61",
   "metadata": {},
   "source": [
    "#### 2.1 POST done passing `classifier` as parameter to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc42fe4f-aac8-45aa-99f0-14220230392b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home = 'http://localhost:8080'\n",
    "classifier_endpoint = '/performance/classifier'\n",
    "headers = {'Content-Type': 'application/json', 'accept': 'application/json'}\n",
    "\n",
    "# POST done at the /performance/{model_from} endpoint\n",
    "res_classifier = requests.post(home + classifier_endpoint, json=class_test_json, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9deaf96-b3d0-4bfa-97f4-b233f13559cd",
   "metadata": {},
   "source": [
    "The answer is returned..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9f7de-b15f-474b-8bb9-ea20ef6285e2",
   "metadata": {},
   "source": [
    "This latency stands for the time required for the model to perform prediction over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c127796-3330-4c5e-bb21-6edcc3b99400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"evaluation_metric\": {\n",
      "        \"f1\": \"0.8936170212765957\"\n",
      "    },\n",
      "    \"satisficing_metrics\": {\n",
      "        \"precision\": \"0.9130434782608695\",\n",
      "        \"recall\": \"0.875\",\n",
      "        \"latency_ms\": \"2.0279884338378906\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res_classifier_parsed = json.loads(res_classifier.text)\n",
    "print(json.dumps(res_classifier_parsed, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323316d9-6190-400c-ac34-53fc23a8f0c7",
   "metadata": {},
   "source": [
    "#### 2.2 POST done passing `regressor` as parameter to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2984a2a-5359-47d8-9f02-8157476fed40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor_endpoint = '/performance/regressor'\n",
    "\n",
    "# POST done at the /performance/{model_from} endpoint\n",
    "res_regressor = requests.post(home + regressor_endpoint, json=regr_test_json, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6cdec-14bc-4001-a673-4419ef925bc1",
   "metadata": {},
   "source": [
    "The answer is returned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6f9e3a-840c-4116-adb5-5688a43880a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"evaluation_metric\": {\n",
      "        \"RMSE\": \"8.018073509187136\"\n",
      "    },\n",
      "    \"satisficing_metrics\": {\n",
      "        \"R2\": \"0.9999597127306887\",\n",
      "        \"correlation\": {\n",
      "            \"statistic\": \"0.9999882061079758\",\n",
      "            \"p-value\": \"0.0\"\n",
      "        },\n",
      "        \"latency_ms\": \"1.0030269622802734\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res_regressor_parsed = json.loads(res_regressor.text)\n",
    "print(json.dumps(res_regressor_parsed, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5df9d-0ac0-4a45-b2eb-e0282d2938dc",
   "metadata": {},
   "source": [
    "### 3. POST request on the `adherence` endpoint only for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac0a63-2dee-48ff-bd4d-797c52ee6897",
   "metadata": {},
   "source": [
    "The idea to create this endpoint is to enable data drifting monitoring. This endpoint performs the Kolmogorov-Smirnov test considering two sample distributions in order to determine the distance between them. Depending on a predefined significance level, it is possible to say whether these distributions come from the same population. When they do not, it is an indicative that the data collected is slowly drifting and <strong>should</strong> harm model performance. It is useful to monitor it to prevent these situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4d9b5-87ef-4f36-be52-fcdf5228fd10",
   "metadata": {},
   "source": [
    "Let this significance level be $\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9219b2f-f74d-4c58-b86d-7d8978699b42",
   "metadata": {},
   "source": [
    "To get to some conclusion, let a null hypothesis consisting in saying both samples <strong>belong</strong> to the same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d5166-993e-46fe-8fad-947a631fb5dd",
   "metadata": {},
   "source": [
    "This way, using <em><strong>scipy.stats.ks_2samp(score_req, score_test)</strong></em> we consider as null hypothesis the fact that the probability scores determined by the classifier model to <strong>both</strong> datasets do come from the same distribution. This implies, hence, that these data were brought by the same population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb6943-e63b-4487-b953-136461250a9c",
   "metadata": {},
   "source": [
    "Therefore, by calculating the KS test metrics, we shall compare <em><strong>p-value</strong></em> with <em><strong>$\\alpha$</strong></em> to either reject or not the null hypothesis\n",
    "\n",
    "<li>If <em><strong>p-value</strong></em> $ > \\alpha$, we do not reject the null hypothesis and the samples <strong>do</strong> come from the same distribution of data</li>\n",
    "<li>If <em><strong>p-value</strong></em> $ <= \\alpha$, we reject the null hypothesis and the samples <strong>do not</strong> come from the same distribution of data</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62cd03-1531-4a81-82a3-d8a442576a64",
   "metadata": {},
   "source": [
    "The KS test uses the <em><strong>statistic</strong></em> metric to define the <em><strong>p-value</strong></em>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b01e5-dd76-4508-974a-37d84e8d8eef",
   "metadata": {},
   "source": [
    "#### 3.1 Get reference data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ed90d-8eb3-494a-a622-24a447721a60",
   "metadata": {},
   "source": [
    "The fitted model expects to predict over datasets that share probabilistic properties with the reference data (the one the model was trained on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652d888d-1b6f-4091-a841-8512d10f7119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_train_file = open('classification_train.json')\n",
    "class_train_json = json.load(class_train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3dfd99-99b2-4bdc-b2a4-e7d274233ddc",
   "metadata": {},
   "source": [
    "#### 3.2 Get predefined testing data and perform POST passing `classifier` as parameter to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0310f48c-83c9-4f5a-adb9-f639a12ded8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(class_test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8cffb41-9b7a-4f71-8655-1aa00ee5fa63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_data = {'reference': class_train_json, 'request': class_test_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492bf634-79e8-4c99-bbec-60d692c51d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_endpoint_adh = '/adherence/classifier'\n",
    "\n",
    "# POST done at the /adherence/{model_from} endpoint\n",
    "res_classifier_adh = requests.post(home + classifier_endpoint_adh, json=json_data, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7b20e-73f2-4be5-9ad3-cd834ccd010e",
   "metadata": {},
   "source": [
    "The answer is returned..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765caaf-500d-4e17-87d1-d424da2c1fb2",
   "metadata": {},
   "source": [
    "The sample datasets do come from the same distribution of data as `p-value` is indeed greater than `.05`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ebc2ce-2251-41fe-9379-5ac10bbc733f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"KStest-result\": {\n",
      "        \"statistic\": 0.04690185436454093,\n",
      "        \"p-value\": 0.6924656909900425\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res_classifier_adh_parsed = json.loads(res_classifier_adh.text)\n",
    "print(json.dumps(res_classifier_adh_parsed, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c14f5-66f6-4ff9-8c8a-3b83d1779eb9",
   "metadata": {},
   "source": [
    "This endpoint could be automated in order to perform this test in a daily basis so that it could trigger alarms whenever there are signs of data drifting as the `p-value` gets lower than the significance level `0.05`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a30d6-9acb-493a-a363-bfe809721c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
